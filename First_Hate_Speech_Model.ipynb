{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First Hate Speech Model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89qx8WuTYl_B"
      },
      "source": [
        "# Model Bias in NLP - Application to Hate Speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6zgrOMthsVK"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzm7BmdgYfkf"
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.text import Tokenizer  \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Bidirectional, GRU, Dropout,Embedding ,Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3l2V3IKZgYS",
        "outputId": "a601692f-99a1-4e12-be03-a8fe17b2cd04"
      },
      "source": [
        "# Download Kaggle Dataset via the Kaggle API\n",
        "\n",
        "kaggle_api = {\"username\":\"bojonas\",\"key\":\"1b3903e6a0f6c0bb4c684ade1e291321\"}\n",
        "\n",
        "import json\n",
        "with open('/content/kaggle.json', 'w') as file:\n",
        "    json.dump(kaggle_api, file)\n",
        "\n",
        "!chmod 600 /content/kaggle.json\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "\n",
        "!kaggle competitions download -c jigsaw-unintended-bias-in-toxicity-classification\n",
        "\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 96% 265M/276M [00:03<00:00, 139MB/s]\n",
            "100% 276M/276M [00:03<00:00, 89.5MB/s]\n",
            "Downloading test_public_expanded.csv.zip to /content\n",
            " 69% 11.0M/15.9M [00:00<00:00, 19.0MB/s]\n",
            "100% 15.9M/15.9M [00:00<00:00, 45.5MB/s]\n",
            "Downloading test_private_expanded.csv.zip to /content\n",
            " 70% 11.0M/15.8M [00:00<00:00, 25.9MB/s]\n",
            "100% 15.8M/15.8M [00:00<00:00, 35.3MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 58% 7.00M/12.1M [00:00<00:00, 71.0MB/s]\n",
            "100% 12.1M/12.1M [00:00<00:00, 77.5MB/s]\n",
            "Downloading toxicity_individual_annotations.csv.zip to /content\n",
            " 77% 50.0M/64.7M [00:00<00:00, 81.3MB/s]\n",
            "100% 64.7M/64.7M [00:00<00:00, 110MB/s] \n",
            "Downloading all_data.csv.zip to /content\n",
            " 97% 315M/326M [00:03<00:00, 95.6MB/s]\n",
            "100% 326M/326M [00:03<00:00, 96.1MB/s]\n",
            "Downloading identity_individual_annotations.csv.zip to /content\n",
            " 90% 11.0M/12.3M [00:00<00:00, 43.7MB/s]\n",
            "100% 12.3M/12.3M [00:00<00:00, 48.6MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/224k [00:00<?, ?B/s]\n",
            "100% 224k/224k [00:00<00:00, 66.6MB/s]\n",
            "Archive:  test_public_expanded.csv.zip\n",
            "  inflating: test_public_expanded.csv  \n",
            "\n",
            "Archive:  identity_individual_annotations.csv.zip\n",
            "  inflating: identity_individual_annotations.csv  \n",
            "\n",
            "Archive:  all_data.csv.zip\n",
            "  inflating: all_data.csv            \n",
            "\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "\n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n",
            "\n",
            "Archive:  test_private_expanded.csv.zip\n",
            "  inflating: test_private_expanded.csv  \n",
            "\n",
            "Archive:  toxicity_individual_annotations.csv.zip\n",
            "  inflating: toxicity_individual_annotations.csv  \n",
            "\n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "\n",
            "8 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIRe244Vi-c6",
        "outputId": "b1f6f2ac-2a9b-4081-e354-bc2ba93fdd36"
      },
      "source": [
        "# Check TPU Device\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.57.231.42:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.57.231.42:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WipKSWhJek5S"
      },
      "source": [
        "# Read training data\n",
        "\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "\n",
        "X = train[\"comment_text\"]\n",
        "Y = train[\"target\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRAvv3t0foAm"
      },
      "source": [
        "# Tokenize to 10'000 words and pad to 100 words per comment\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"UNK\")\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "X = pad_sequences(X, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCRc-lrmhK1h"
      },
      "source": [
        "# Train Test split for training/testing\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCG-jD5QhWij",
        "outputId": "8e44b425-fe22-493d-9025-879d814f1d13"
      },
      "source": [
        "# Define Keras LSTM Model with embedding layer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=50, input_length=100))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 50)           500000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               91648     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 591,777\n",
            "Trainable params: 591,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NKUGelQkEyv",
        "outputId": "56ae5f15-f849-4791-d8f8-966cefadefa9"
      },
      "source": [
        "# Getting TPU Adresses\n",
        "\n",
        "try:\n",
        " device_name = os.environ[\"COLAB_TPU_ADDR\"]\n",
        " TPU_ADDRESS = \"grpc://\" + device_name\n",
        " print(\"Found TPU at: {}\".format(TPU_ADDRESS))\n",
        "except KeyError:\n",
        " print(\"TPU not found\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found TPU at: grpc://10.57.231.42:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__NrU2PEhyVw"
      },
      "source": [
        "opt = tf.optimizers.Adam()\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gcIBmR5mleO"
      },
      "source": [
        "train_dataset_X = tf.data.Dataset.from_tensors(X_train)\n",
        "train_dataset_Y = tf.data.Dataset.from_tensors(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYGX-p2akq6-",
        "outputId": "854a7807-7c39-47ed-f2c6-86b5d720f1c0"
      },
      "source": [
        "model.fit(X_train,Y_train,batch_size=64, epochs=7, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "22561/22561 [==============================] - 2767s 122ms/step - loss: 0.2482 - acc: 0.7008 - val_loss: 0.2443 - val_acc: 0.7007\n",
            "Epoch 2/7\n",
            "11900/22561 [==============>...............] - ETA: 19:55 - loss: 0.2423 - acc: 0.7009"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}